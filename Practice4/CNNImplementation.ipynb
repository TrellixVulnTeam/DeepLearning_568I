{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You will build the components of a Convolutional Neural Network (CNN)\n",
    "from scratch. Specfically, this part will familiarize you with implementing the for-\n",
    "ward and backward pass of the convolutional and max pooling layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "import os\n",
    "from cs231n.fast_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "from utils import report, run_tasks, makedirs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def task1():\n",
    "    '''\n",
    "    The core of a convolutional network is the convolution operation. In the file cs231n/layers.py,\n",
    "    implement the forward pass for the convolution layer in the function conv_forward_naive.\n",
    "    You don't have to worry too much about efficiency at this point; just write the code in whatever way you find most clear.\n",
    "    You can test your implementation by running the following\n",
    "    '''\n",
    "    print('*'*30+' Task 1 '+'*'*30)\n",
    "    x_shape = (2, 3, 4, 4)\n",
    "    w_shape = (3, 3, 4, 4)\n",
    "    x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "    w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "    b = np.linspace(-0.1, 0.2, num=3)\n",
    "\n",
    "    conv_param = {'stride': 2, 'pad': 1}\n",
    "    out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "    correct_out = np.array([[[[[-0.08759809, -0.10987781],\n",
    "                            [-0.18387192, -0.2109216 ]],\n",
    "                            [[ 0.21027089,  0.21661097],\n",
    "                            [ 0.22847626,  0.23004637]],\n",
    "                            [[ 0.50813986,  0.54309974],\n",
    "                            [ 0.64082444,  0.67101435]]],\n",
    "                            [[[-0.98053589, -1.03143541],\n",
    "                            [-1.19128892, -1.24695841]],\n",
    "                            [[ 0.69108355,  0.66880383],\n",
    "                            [ 0.59480972,  0.56776003]],\n",
    "                            [[ 2.36270298,  2.36904306],\n",
    "                            [ 2.38090835,  2.38247847]]]]])\n",
    "\n",
    "    # Compare your output to ours; difference should be around 1e-8\n",
    "    print ('Testing conv_forward_naive')\n",
    "    print ('difference: ', rel_error(out, correct_out))\n",
    "    print('*'*30+' Task 1 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 1 ******************************\n",
      "Testing conv_forward_naive\n",
      "difference:  2.2121476417505994e-08\n",
      "****************************** Task 1 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task1()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def task2():\n",
    "    '''\n",
    "    Implement the backward pass for the convolution operation in the function conv_backward_naive in the file cs231n/layers.py.\n",
    "    Again, you don't need to worry too much about computational efficiency.\n",
    "    When you are done, run the following to check your backward pass with a numeric gradient check.\n",
    "    '''\n",
    "    print('*'*30+' Task 2 '+'*'*30)\n",
    "    x = np.random.randn(4, 3, 5, 5)\n",
    "    w = np.random.randn(2, 3, 3, 3)\n",
    "    b = np.random.randn(2,)\n",
    "    dout = np.random.randn(4, 2, 5, 5)\n",
    "    conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "    dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "    dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "    db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "    out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "    dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "    # Your errors should be around 1e-9'\n",
    "    print ('Testing conv_backward_naive function')\n",
    "    print ('dx error: ', rel_error(dx, dx_num))\n",
    "    print ('dw error: ', rel_error(dw, dw_num))\n",
    "    print ('db error: ', rel_error(db, db_num))\n",
    "    print('*'*30+' Task 2 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 2 ******************************\n",
      "Testing conv_backward_naive function\n",
      "dx error:  6.606084848186138e-09\n",
      "dw error:  3.543617837843817e-10\n",
      "db error:  1.3524159510496563e-11\n",
      "****************************** Task 2 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task2()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def task3():\n",
    "    '''\n",
    "    Implement the forward pass for the max-pooling operation in the function max_pool_forward_naive in the file cs231n/layers.py.\n",
    "    Again, don't worry too much about computational efficiency. Check your implementation by running the following:\n",
    "    '''\n",
    "    print('*'*30+' Task 3 '+'*'*30)\n",
    "    x_shape = (2, 3, 4, 4)\n",
    "    x = np.linspace(-0.3, 0.4, num=np.prod(x_shape)).reshape(x_shape)\n",
    "    pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "    out, _ = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "    correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                            [-0.20421053, -0.18947368]],\n",
    "                            [[-0.14526316, -0.13052632],\n",
    "                            [-0.08631579, -0.07157895]],\n",
    "                            [[-0.02736842, -0.01263158],\n",
    "                            [ 0.03157895,  0.04631579]]],\n",
    "                            [[[ 0.09052632,  0.10526316],\n",
    "                            [ 0.14947368,  0.16421053]],\n",
    "                            [[ 0.20842105,  0.22315789],\n",
    "                            [ 0.26736842,  0.28210526]],\n",
    "                            [[ 0.32631579,  0.34105263],\n",
    "                            [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "    # Compare your output with ours. Difference should be around 1e-8.\n",
    "    print ('Testing max_pool_forward_naive function:')\n",
    "    print ('difference: ', rel_error(out, correct_out))\n",
    "    print('*'*30+' Task 3 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 3 ******************************\n",
      "Testing max_pool_forward_naive function:\n",
      "difference:  4.1666665157267834e-08\n",
      "****************************** Task 3 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task3()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def task4():\n",
    "    '''\n",
    "    Implement the backward pass for the max-pooling operation in the function max_pool_backward_naive in the file cs231n/layers.py.\n",
    "    You don't need to worry about computational efficiency. Check your implementation with numeric gradient checking by running the following:\n",
    "    '''\n",
    "    print('*'*30+' Task 4 '+'*'*30)\n",
    "    x = np.random.randn(3, 2, 8, 8)\n",
    "    dout = np.random.randn(3, 2, 4, 4)\n",
    "    pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "    dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "    out, cache = max_pool_forward_naive(x, pool_param)\n",
    "    dx = max_pool_backward_naive(dout, cache)\n",
    "    print ('Testing max_pool_backward_naive function:')\n",
    "    print ('dx error: ', rel_error(dx, dx_num))\n",
    "    print('*'*30+' Task 4 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 4 ******************************\n",
      "Testing max_pool_backward_naive function:\n",
      "dx error:  3.2756272224694605e-12\n",
      "****************************** Task 4 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task4()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def task5():\n",
    "    '''\n",
    "    In the file cs231n/layers.py, implement the forward pass for spatial batch normalization in the function spatial_batchnorm_forward.\n",
    "    Check your implementation by running the following\n",
    "    '''\n",
    "    print('*'*30+' Task 5 '+'*'*30)\n",
    "    # Check the training-time forward pass by checking means and variances\n",
    "    # of features both before and after spatial batch normalization\n",
    "\n",
    "    N, C, H, W = 2, 3, 4, 5\n",
    "    x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "\n",
    "    print('Before spatial batch normalization:')\n",
    "    print('  Shape: ', x.shape)\n",
    "    print('  Means: ', x.mean(axis=(0, 2, 3)))\n",
    "    print('  Stds: ', x.std(axis=(0, 2, 3)))\n",
    "\n",
    "    # Means should be close to zero and stds close to one\n",
    "    gamma, beta = np.ones(C), np.zeros(C)\n",
    "    bn_param = {'mode': 'train'}\n",
    "    out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "    print('After spatial batch normalization:')\n",
    "    print('  Shape: ', out.shape)\n",
    "    print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
    "    print('  Stds: ', out.std(axis=(0, 2, 3)))\n",
    "\n",
    "    # Means should be close to beta and stds close to gamma\n",
    "    gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n",
    "    out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "    print('After spatial batch normalization (nontrivial gamma, beta):')\n",
    "    print('  Shape: ', out.shape)\n",
    "    print('  Means: ', out.mean(axis=(0, 2, 3)))\n",
    "    print('  Stds: ', out.std(axis=(0, 2, 3)))\n",
    "    print('*'*30+' Task 5 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 5 ******************************\n",
      "Before spatial batch normalization:\n",
      "  Shape:  (2, 3, 4, 5)\n",
      "  Means:  [10.78493855 10.82172232 10.93375494]\n",
      "  Stds:  [4.0284838  4.04344873 4.09148095]\n",
      "After spatial batch normalization:\n",
      "  Shape:  (2, 3, 4, 5)\n",
      "  Means:  [-1.60982339e-16  1.30451205e-16 -9.10382880e-16]\n",
      "  Stds:  [0.99999969 0.99999969 0.9999997 ]\n",
      "After spatial batch normalization (nontrivial gamma, beta):\n",
      "  Shape:  (2, 3, 4, 5)\n",
      "  Means:  [6. 7. 8.]\n",
      "  Stds:  [2.99999908 3.99999878 4.99999851]\n",
      "****************************** Task 5 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task5()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def task6():\n",
    "    '''\n",
    "    In the file cs231n/layers.py, implement the backward pass for spatial batch normalization in the function spatial_batchnorm_backward.\n",
    "    Run the following to check your implementation using a numeric gradient check:\n",
    "    '''\n",
    "    print('*'*30+' Task 6 '+'*'*30)\n",
    "    N, C, H, W = 2, 3, 4, 5\n",
    "    x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "    gamma = np.random.randn(C)\n",
    "    beta = np.random.randn(C)\n",
    "    dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "    bn_param = {'mode': 'train'}\n",
    "    fx = lambda x: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "    fg = lambda a: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "    fb = lambda b: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "\n",
    "    dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "    da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "    db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "    _, cache = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "    dx, dgamma, dbeta = spatial_batchnorm_backward(dout, cache)\n",
    "    print('dx error: ', rel_error(dx_num, dx))\n",
    "    print('dgamma error: ', rel_error(da_num, dgamma))\n",
    "    print('dbeta error: ', rel_error(db_num, dbeta))\n",
    "    print('*'*30+' Task 6 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 6 ******************************\n",
      "dx error:  3.2789814252461245e-08\n",
      "dgamma error:  6.930479390312331e-12\n",
      "dbeta error:  3.2761151560675645e-12\n",
      "****************************** Task 6 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task6()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}