{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "You will implement batch normalization for fully connected networks.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "import os\n",
    "from utils import report, run_tasks, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def task1():\n",
    "    '''\n",
    "    Batch normalization: Forward In the file cs231n/layers.py,\n",
    "    implement the batch normalization forward pass in the function batchnorm_forward.\n",
    "    Once you have done so, run the following to test your implementation.\n",
    "    Check the training-time forward pass by checking means and variances of features both before and after batch normalization\n",
    "    '''\n",
    "    print('*'*30+' Task 1 '+'*'*30)\n",
    "    #Simulate the forward pass for a two-layer network\n",
    "    N, D1, D2, D3 = 200, 50, 60, 3\n",
    "    X = np.random.randn(N, D1)\n",
    "    W1 = np.random.randn(D1, D2)\n",
    "    W2 = np.random.randn(D2, D3)\n",
    "    a = np.maximum(0, X.dot(W1)).dot(W2)\n",
    "\n",
    "    print ('Before batch normaliation:')\n",
    "    print ('  means: ', a.mean(axis=0))\n",
    "    print ('  stds: ', a.std(axis=0))\n",
    "\n",
    "    # Means should be close to zero and stds close to one\n",
    "    print ('After batch normalization (gamma=1, beta=0)')\n",
    "    a_norm, _ = batchnorm_forward(a, np.ones(D3), np.zeros(D3), {'mode': 'train'})\n",
    "    print ('  mean: ', a_norm.mean(axis=0))\n",
    "    print ('  std: ', a_norm.std(axis=0))\n",
    "\n",
    "    # Now means should be close to beta and stds close to gamma\n",
    "    gamma = np.asarray([1.0, 2.0, 3.0])\n",
    "    beta = np.asarray([11.0, 12.0, 13.0])\n",
    "    a_norm, _ = batchnorm_forward(a, gamma, beta, {'mode': 'train'})\n",
    "    print ('After batch normalization (nontrivial gamma, beta)')\n",
    "    print ('  means: ', a_norm.mean(axis=0))\n",
    "    print ('  stds: ', a_norm.std(axis=0))\n",
    "    print('*'*30+' Task 1 completed'+'*'*30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 1 ******************************\n",
      "Before batch normaliation:\n",
      "  means:  [-12.39094475  33.15835779  22.26310147]\n",
      "  stds:  [24.51509527 36.77094844 32.37334076]\n",
      "After batch normalization (gamma=1, beta=0)\n",
      "  mean:  [-6.55031585e-17  1.00891517e-16 -2.72004641e-17]\n",
      "  std:  [0.99999999 1.         1.        ]\n",
      "After batch normalization (nontrivial gamma, beta)\n",
      "  means:  [11. 12. 13.]\n",
      "  stds:  [0.99999999 1.99999999 2.99999999]\n",
      "****************************** Task 1 completed******************************\n"
     ]
    }
   ],
   "source": [
    "task1()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def task2():\n",
    "    '''\n",
    "    Fully Connected Nets with Batch Normalization Now that you have a working implementation\n",
    "    for batch normalization, go back to your FullyConnectedNet in the file\n",
    "    cs2312n/classifiers/fc_net.py. Modify your implementation to add batch normalization.\n",
    "    Concretely, when the flag use_batchnorm is True in the constructor, you should insert a\n",
    "    batch normalization layer before each ReLU nonlinearity.\n",
    "    The outputs from the last layer of the network should not be normalized.\n",
    "    Once you are done, run the following to gradient-check your implementation.\n",
    "    To make your life easier, you are given an additional helper layer in the file\n",
    "    cs231n/layer_utils.py called affine_bn_relu_forward and affine_bn_relu_backward.\n",
    "    You have to update 3 parts in the loss function:\n",
    "    first part is fc_net.py- initialization\n",
    "    second part is forward pass in loss function\n",
    "    third part is backward pass in loss function\n",
    "    '''\n",
    "    print('*'*30+' Task 3 '+'*'*30)\n",
    "    N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "    X = np.random.randn(N, D)\n",
    "    y = np.random.randint(C, size=(N,))\n",
    "\n",
    "    for reg in [0, 3.14]:\n",
    "        print ('Running check with reg = ', reg)\n",
    "        model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                                reg=reg, weight_scale=5e-2, dtype=np.float64,\n",
    "                                use_batchnorm=True)\n",
    "\n",
    "        loss, grads = model.loss(X, y)\n",
    "        print ('Initial loss: ', loss)\n",
    "\n",
    "        for name in sorted(grads):\n",
    "            f = lambda _: model.loss(X, y)[0]\n",
    "            grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "            print ('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))\n",
    "        if reg == 0: print ()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Task 3 ******************************\n",
      "Running check with reg =  0\n",
      "Initial loss:  2.2713124310221806\n",
      "W1 relative error: 7.25e-05\n",
      "W2 relative error: 2.91e-06\n",
      "W3 relative error: 3.41e-10\n",
      "b1 relative error: 2.22e-03\n",
      "b2 relative error: 3.33e-08\n",
      "b3 relative error: 1.67e-10\n",
      "beta1 relative error: 9.18e-09\n",
      "beta2 relative error: 1.06e-07\n",
      "gamma1 relative error: 4.48e-09\n",
      "gamma2 relative error: 3.51e-08\n",
      "\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  7.18603095655944\n",
      "W1 relative error: 1.10e-04\n",
      "W2 relative error: 4.83e-06\n",
      "W3 relative error: 2.87e-08\n",
      "b1 relative error: 6.94e-10\n",
      "b2 relative error: 5.55e-09\n",
      "b3 relative error: 1.65e-10\n",
      "beta1 relative error: 8.49e-08\n",
      "beta2 relative error: 2.97e-08\n",
      "gamma1 relative error: 1.07e-07\n",
      "gamma2 relative error: 1.17e-07\n"
     ]
    }
   ],
   "source": [
    "task2()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}